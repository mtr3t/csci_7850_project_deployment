{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hrr_persistant_memory as hrr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maze enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maze enviornment\n",
    "#  l    42    r\n",
    "# rg    32    gg\n",
    "# 20 21 22 23 24\n",
    "#      ]12[ \n",
    "#  0  1  2  3  4\n",
    "#      - 8\n",
    "#      -18\n",
    "\n",
    "def maze(state):\n",
    "    if state == -18:\n",
    "        return ['up']\n",
    "    if state == -8:\n",
    "        return ['up', 'down']\n",
    "    if state == 0:\n",
    "        return ['right']\n",
    "    if state == 1:\n",
    "        return ['right', 'left']\n",
    "    if state == 2:\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    if state == 3:\n",
    "        return ['right', 'left']\n",
    "    if state == 4:\n",
    "        return ['left']\n",
    "    if state == 12:\n",
    "        return ['up', 'down']\n",
    "    if state == 20:\n",
    "        return ['right']\n",
    "    if state == 21:\n",
    "        return ['right', 'left']\n",
    "    if state == 22:\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    if state == 23:\n",
    "        return ['right', 'left']\n",
    "    if state == 24:\n",
    "        return ['left']\n",
    "    if state == 32:\n",
    "        return ['up', 'down']\n",
    "    if state == 42:\n",
    "        return ['down']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 1.0\n",
    "reward = 1.0\n",
    "\n",
    "gamma = 0.5\n",
    "alpha = 0.1\n",
    "lambd = 0.0\n",
    "epsilon = 0.0\n",
    "\n",
    "states = 12\n",
    "episodes = 1 #10000\n",
    "\n",
    "hrr_size = 1024\n",
    "non_goal_states = 0\n",
    "\n",
    "# drop in states\n",
    "drop_in_states = [0]\n",
    "gates = ['open', 'closed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gate(state, signal, w_m, gate_action):\n",
    "    string = 'state_'  + str(state) + \"*\" + \\\n",
    "             'signal_' + str(signal) + \"*\" + \\\n",
    "             'w_m_' + str(w_m) + \"*\" + \\\n",
    "             'gate_action_' + str(gate_action)\n",
    "    encoded = np.array([memory.encode(string)])\n",
    "    return(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input gate\n",
    "\n",
    "def q_input_gate(state, signal, w_m):\n",
    "    max_value = -99999\n",
    "    \n",
    "    if np.random.random() < epsilon:\n",
    "        gate = np.random.choice(gates)\n",
    "        hrr = encode_gate(state, signal, w_m, gate)\n",
    "        value = model_input_gate.predict(hrr)[0,0] + bias\n",
    "        return value, hrr, gate\n",
    "    else:\n",
    "        for gate_action in gates:\n",
    "            hrr = encode_gate(state, signal, w_m, gate_action)\n",
    "            value = model_input_gate.predict(hrr)[0,0] + bias\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_hrr = hrr\n",
    "                max_gate = gate_action\n",
    "        return  max_value, max_hrr, max_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output gate\n",
    "\n",
    "def q_output_gate(state, signal, w_m):\n",
    "    max_value = -99999\n",
    "    \n",
    "    if np.random.random() < epsilon:\n",
    "        gate = np.random.choice(gates)\n",
    "        hrr = encode_gate(state, signal, w_m, gate)\n",
    "        value = model_output_gate.predict(hrr)[0,0] + bias\n",
    "        return value, hrr, gate\n",
    "    else:\n",
    "        for gate_action in gates:\n",
    "            hrr = encode_gate(state, signal, w_m, gate_action)\n",
    "            value = model_output_gate.predict(hrr)[0,0] + bias\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_hrr = hrr\n",
    "                max_gate = gate_action\n",
    "        return  max_value, max_hrr, max_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move gate\n",
    "\n",
    "def encode_move(state, signal, w_m, phyical_action):\n",
    "    string = 'state_'  + str(state) + \"*\" + \\\n",
    "             'signal_' + str(signal) + \"*\" + \\\n",
    "             'w_m_' + str(w_m) + \"*\" + \\\n",
    "             'phyical_action_' + str(phyical_action)\n",
    "    encoded = np.array([memory.encode(string)])\n",
    "    return(encoded)\n",
    "\n",
    "def q_move(state, signal, w_m):\n",
    "    max_value = -99999\n",
    "    if np.random.random() < epsilon:\n",
    "        phyical_move = np.random.choice(actions)\n",
    "        hrr = encode_move(state, signal, w_m, phyical_move)\n",
    "        value = model_move.predict(hrr)[0,0] + bias\n",
    "        return value, hrr, phyical_move  \n",
    "    else:\n",
    "        for phyical_action in actions:\n",
    "            hrr = encode_move(state, signal, w_m, phyical_action)\n",
    "            value = model_move.predict(hrr)[0,0] + bias\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "                max_hrr = hrr\n",
    "                max_action = phyical_action\n",
    "        return  max_value, max_hrr, max_action\n",
    "\n",
    "def q_move_max(state, signal, w_m):\n",
    "    max_value = -99999\n",
    "#     print(state, actions)\n",
    "    for phyical_action in actions:    \n",
    "        hrr = encode_move(state, signal, w_m, phyical_action)\n",
    "        value = model_move.predict(hrr)[0,0] + bias\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            max_hrr = hrr\n",
    "            max_action = phyical_action\n",
    "    return  max_value, max_hrr, max_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the memory created when the code was first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = hrr.LTM(prefix=\"my_hrrs\", N=hrr_size, normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the models created when the code was first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_gate = keras.models.load_model(\"model_input_gate.h5\")\n",
    "model_output_gate = keras.models.load_model(\"model_output_gate.h5\")\n",
    "model_move = keras.models.load_model(\"model_move.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run model on each color to see what policy the agent learned\n",
    "#### red below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = 0       \n",
    "current_signal = 'red'\n",
    "\n",
    "if current_signal == 'red':\n",
    "    goal_state = 20\n",
    "if current_signal == 'green':\n",
    "    goal_state = 24\n",
    "if current_signal == 'purple':\n",
    "    goal_state = 42\n",
    "\n",
    "# clear out working memory amd move content\n",
    "current_w_m = ''\n",
    "recall = 'not_remembering'\n",
    "\n",
    "for step in range(states):\n",
    "    print(step, current_state)\n",
    "    # set for same start\n",
    "    if current_state == goal_state:\n",
    "        if color_start == 0:\n",
    "            sub_optimal_steps.append(step - 6)\n",
    "        break\n",
    "    else:\n",
    "        if step == (states-1):\n",
    "            sub_optimal_steps.append(states)\n",
    "\n",
    "    actions = maze(current_state)\n",
    "\n",
    "    if current_signal != '':\n",
    "\n",
    "        # need to make this color\n",
    "        back_up = current_signal\n",
    "        current_signal = 'color'\n",
    "\n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_input_gate(current_state, current_signal, recall)\n",
    "\n",
    "        current_signal = back_up\n",
    "\n",
    "        move_value, \\\n",
    "        move_hrr, \\\n",
    "        move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_gate_hrr = gate_hrr\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            current_w_m = current_signal\n",
    "            recall = 'remembering'\n",
    "\n",
    "        current_signal = ''            \n",
    "\n",
    "        # make move to next state      \n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        # now current_state is the next state so check new actions\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value\n",
    "\n",
    "    else:                \n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            recall = current_w_m\n",
    "            current_w_m = ''\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "            recall = 'memory_used'\n",
    "        else:\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "        previous_gate_hrr = gate_hrr\n",
    "\n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we can see red did not behave well\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### green below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = 0       \n",
    "current_signal = 'green'\n",
    "\n",
    "if current_signal == 'red':\n",
    "    goal_state = 20\n",
    "if current_signal == 'green':\n",
    "    goal_state = 24\n",
    "if current_signal == 'purple':\n",
    "    goal_state = 42\n",
    "\n",
    "# clear out working memory amd move content\n",
    "current_w_m = ''\n",
    "recall = 'not_remembering'\n",
    "\n",
    "for step in range(states):\n",
    "    print(step, current_state)\n",
    "    # set for same start\n",
    "    if current_state == goal_state:\n",
    "        if color_start == 0:\n",
    "            sub_optimal_steps.append(step - 6)\n",
    "        break\n",
    "    else:\n",
    "        if step == (states-1):\n",
    "            sub_optimal_steps.append(states)\n",
    "\n",
    "    actions = maze(current_state)\n",
    "\n",
    "    if current_signal != '':\n",
    "\n",
    "        # need to make this color\n",
    "        back_up = current_signal\n",
    "        current_signal = 'color'\n",
    "\n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_input_gate(current_state, current_signal, recall)\n",
    "\n",
    "        current_signal = back_up\n",
    "\n",
    "        move_value, \\\n",
    "        move_hrr, \\\n",
    "        move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_gate_hrr = gate_hrr\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            current_w_m = current_signal\n",
    "            recall = 'remembering'\n",
    "\n",
    "        current_signal = ''            \n",
    "\n",
    "        # make move to next state      \n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        # now current_state is the next state so check new actions\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value\n",
    "\n",
    "    else:                \n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            recall = current_w_m\n",
    "            current_w_m = ''\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "            recall = 'memory_used'\n",
    "        else:\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "        previous_gate_hrr = gate_hrr\n",
    "\n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we can see green is sub-optimal but still solving the task\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### purple below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = 0       \n",
    "current_signal = 'purple'\n",
    "\n",
    "if current_signal == 'red':\n",
    "    goal_state = 20\n",
    "if current_signal == 'green':\n",
    "    goal_state = 24\n",
    "if current_signal == 'purple':\n",
    "    goal_state = 42\n",
    "\n",
    "# clear out working memory amd move content\n",
    "current_w_m = ''\n",
    "recall = 'not_remembering'\n",
    "\n",
    "for step in range(states):\n",
    "    print(step, current_state)\n",
    "    # set for same start\n",
    "    if current_state == goal_state:\n",
    "        if color_start == 0:\n",
    "            sub_optimal_steps.append(step - 6)\n",
    "        break\n",
    "    else:\n",
    "        if step == (states-1):\n",
    "            sub_optimal_steps.append(states)\n",
    "\n",
    "    actions = maze(current_state)\n",
    "\n",
    "    if current_signal != '':\n",
    "\n",
    "        # need to make this color\n",
    "        back_up = current_signal\n",
    "        current_signal = 'color'\n",
    "\n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_input_gate(current_state, current_signal, recall)\n",
    "\n",
    "        current_signal = back_up\n",
    "\n",
    "        move_value, \\\n",
    "        move_hrr, \\\n",
    "        move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_gate_hrr = gate_hrr\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            current_w_m = current_signal\n",
    "            recall = 'remembering'\n",
    "\n",
    "        current_signal = ''            \n",
    "\n",
    "        # make move to next state      \n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        # now current_state is the next state so check new actions\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value\n",
    "\n",
    "    else:                \n",
    "        gate_value, \\\n",
    "        gate_hrr, \\\n",
    "        gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "\n",
    "        if gate_action == 'open':\n",
    "            recall = current_w_m\n",
    "            current_w_m = ''\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "            recall = 'memory_used'\n",
    "        else:\n",
    "            move_value, \\\n",
    "            move_hrr, \\\n",
    "            move_action = q_move(current_state, current_signal, recall)\n",
    "\n",
    "        previous_state = current_state\n",
    "        previous_move_value = move_value\n",
    "        previous_move_hrr = move_hrr\n",
    "        previous_gate_hrr = gate_hrr\n",
    "\n",
    "        if (move_action == \"left\"):\n",
    "            current_state = (current_state-1)\n",
    "        if (move_action == \"right\"):\n",
    "            current_state = (current_state+1)\n",
    "        if (move_action == \"up\"):\n",
    "            current_state = (current_state+10)\n",
    "        if (move_action == \"down\"):\n",
    "            current_state = (current_state-10)\n",
    "\n",
    "        actions = maze(current_state)\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            target = reward\n",
    "        else:\n",
    "            if recall == 'remembering':\n",
    "                _, _, gate_action = q_output_gate(current_state, current_signal, recall)\n",
    "            else:\n",
    "                gate_action = 'closed'\n",
    "\n",
    "            if gate_action == 'open':\n",
    "                save_recall = recall\n",
    "                recall = current_w_m\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "                recall = save_recall\n",
    "            else:\n",
    "                move_value, _, _ = q_move_max(current_state, current_signal, recall)\n",
    "\n",
    "            target = non_goal_states + gamma * move_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## purple did great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_count = np.load('ep_count.npy', allow_pickle=True)\n",
    "final_arr = np.load('final_arr.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots to make advisor happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(final_arr)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Sub-optimal Steps')\n",
    "# plt.savefig('red_green_purple.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
